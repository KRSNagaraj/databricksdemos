{"cells":[{"cell_type":"markdown","source":["# MNIST demo using Keras CNN\n\n**Purpose**: Trains a simple ConvNet on the MNIST dataset using Keras using [Databricks Runtime for Machine Learning](https://databricks.com/blog/2018/06/05/distributed-deep-learning-made-simple.html)\n\n**Source**: [`keras/examples/mnist_cnn.py`](https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py)"],"metadata":{}},{"cell_type":"code","source":["import warnings\nwarnings.filterwarnings(\"ignore\")"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["import keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras import backend as K\n\n\n# Use TensorFlow Backend\nimport tensorflow as tf\ntf.set_random_seed(42) # For reproducibility"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":["## Source Data: MNIST\nThese set of cells are based on the TensorFlow's [MNIST for ML Beginners](https://www.tensorflow.org/versions/r0.9/tutorials/mnist/beginners/index.html). \n\nIn reference to `from keras.datasets import mnist` in the previous cell:\n\nThe purpose of this notebook is to use Keras (with TensorFlow backend) to **automate the identification of handwritten digits** from the  [MNIST Database of Handwritten Digits](http://yann.lecun.com/exdb/mnist/) database. The source of these handwritten digits is from the National Institute of Standards and Technology (NIST) Special Database 3 (Census Bureau employees) and Special Database 1 (high-school students).\n\n<img src=\"https://www.tensorflow.org/versions/r0.9/images/MNIST.png\" width=\"300\"/>"],"metadata":{}},{"cell_type":"code","source":["# -----------------------------------------------------------\n# Hyperparameters\nbatch_size = 128\nnum_classes = 10\nepochs = 12\n\n\n# -----------------------------------------------------------\n# Image Datasets\n\n# input image dimensions\nimg_rows, img_cols = 28, 28\n\n# the data, split between train and test sets\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nif K.image_data_format() == 'channels_first':\n    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n    input_shape = (1, img_rows, img_cols)\nelse:\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n    input_shape = (img_rows, img_cols, 1)\n\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255\nprint('x_train shape:', x_train.shape)\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\n\n# convert class vectors to binary class matrices\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":["## What is the image?\nWithin this dataset, this 28px x 28px 3D structure has been flattened into an array of size 784. \n\n* `x_` contains the handwritten digit \n* `y_` contains the labels\n* `_train` contains the 60,000 training samples\n* `_test` contains the 10,000 test samples\n\n\nFor example, if you take the `25168`th element, the label for it is `y_train[25168,:]` indicates its the value `9`.\n\n&nbsp;"],"metadata":{}},{"cell_type":"code","source":["# One-Hot Vector for y_train = 25168 representing the number 9 \n#  The nth-digit will be represented as a vector which is 1 in the nth dimensions. \ny_train[25168,:]"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":["`x_train[25168,:]` is the array of 784 digits numerically representing the handwritten digit number `9`.\n\n&nbsp;"],"metadata":{}},{"cell_type":"code","source":["from __future__ import print_function\n\n# This is the extracted array for x_train = 25168 from the training matrix\nxt_25168 = x_train[25168,:]\n\nprint(xt_25168)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["Let's print it as 28 x 28\n\n&nbsp;"],"metadata":{}},{"cell_type":"code","source":["# As this is a 28 x 28 image, let's print it out this way\ntxt = \"\"\nfor i in range (0, 27):\n   for j in range(0, 27):\n      val = \"%.3f\" % xt_25168[i,j]\n      txt += str(val).replace(\"[\", \"\").replace(\"]\", \"\") + \", \"\n   \n   print(txt)\n   txt = \"\""],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["You can sort of see the number **9** in there, but let's add a color-scale (the higher the number, the darker the value), you will get the following matrix:\n\n<img src=\"https://dennyglee.files.wordpress.com/2018/09/nine.png\" width=500/>\n\nHere, you can access the [full-size version](https://dennyglee.files.wordpress.com/2018/09/nine.png) of this image."],"metadata":{}},{"cell_type":"markdown","source":["## Oh where art thou GPU?\n\nOr **[How can I run Keras on GPU?](https://keras.io/getting-started/faq/#how-can-i-run-keras-on-gpu)**: If you are running on the TensorFlow backends, your code will automatically run on GPU if any available GPU is detected."],"metadata":{}},{"cell_type":"code","source":["# Check for any available GPUs\nK.tensorflow_backend._get_available_gpus()"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["from tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":["## How fast did you say?\n\n| Processor | Duration |\n| --------- | -------- |\n| GPU       | 1.87min  |\n| CPU       | 23.08min |"],"metadata":{}},{"cell_type":"markdown","source":["## Convolutional Neural Networks\n![](https://dennyglee.files.wordpress.com/2018/09/keras-cnn-activate.png)\n\n1. The input layer is a grey scale image of 28x28 pixels. \n2. The first convolution layer maps one grayscale image to 32 feature maps using the activation function\n3. The second convolution layer maps the image to 64 feature maps using the activation function\n4. The pooling layer down samples image by 2x so you have a 14x14 matrix \n5. The first dropout layer delete random neurons (regularization technique to avoid overfitting)\n6. The fully connected feed-forward maps the features with 128 neurons in the hidden layer\n7. The second dropout layer delete random neurons (regularization technique to avoid overfitting)\n8. Apply `softmax` with 10 hidden layers to identify digit."],"metadata":{}},{"cell_type":"code","source":["def runCNN(activation, verbose):\n  # Building up our CNN\n  model = Sequential()\n  \n  # Convolution Layer\n  model.add(Conv2D(32, kernel_size=(3, 3),\n                 activation=activation,\n                 input_shape=input_shape)) \n  \n  # Convolution layer\n  model.add(Conv2D(64, (3, 3), activation=activation))\n  \n  # Pooling with stride (2, 2)\n  model.add(MaxPooling2D(pool_size=(2, 2)))\n  \n  # Delete neuron randomly while training (remain 75%)\n  #   Regularization technique to avoid overfitting\n  model.add(Dropout(0.25))\n  \n  # Flatten layer \n  model.add(Flatten())\n  \n  # Fully connected Layer\n  model.add(Dense(128, activation=activation))\n  \n  # Delete neuron randomly while training (remain 50%) \n  #   Regularization technique to avoid overfitting\n  model.add(Dropout(0.5))\n  \n  # Apply Softmax\n  model.add(Dense(num_classes, activation='softmax'))\n\n  # Loss function (crossentropy) and Optimizer (Adadelta)\n  model.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n\n  # Fit our model\n  model.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=verbose,\n          validation_data=(x_test, y_test))\n\n  # Evaluate our model\n  score = model.evaluate(x_test, y_test, verbose=0)\n  \n  # Return\n  return score"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":["### Using sigmoid"],"metadata":{}},{"cell_type":"code","source":["score_sigmoid = runCNN('sigmoid', 0)\nprint('Test loss:', score_sigmoid[0])\nprint('Test accuracy:', score_sigmoid[1])"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":["### Using tanh"],"metadata":{}},{"cell_type":"code","source":["score_tanh = runCNN('tanh', 0)\nprint('Test loss:', score_tanh[0])\nprint('Test accuracy:', score_tanh[1])"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":["### Using ReLu"],"metadata":{}},{"cell_type":"code","source":["score_relu = runCNN('relu', 1)"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["print('Test loss:', score_relu[0])\nprint('Test accuracy:', score_relu[1])"],"metadata":{},"outputs":[],"execution_count":25}],"metadata":{"name":"Keras MNIST CNN","notebookId":2960220603347397},"nbformat":4,"nbformat_minor":0}
